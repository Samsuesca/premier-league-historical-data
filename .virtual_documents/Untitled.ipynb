import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_premier_league_season(url):
    """
    Extrae la tabla de clasificación de una temporada de Premier League desde Wikipedia
    """
    # Hacer la petición HTTP
    response = requests.get(url)
    response.encoding = 'utf-8'
    
    # Parsear el HTML
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Encontrar la tabla de clasificación
    # Buscar tabla con clase 'wikitable' que contenga 'Clasificación'
    tables = soup.find_all('table', {'class': 'wikitable'})
    
    clasificacion_table = None
    for table in tables:
        # Buscar en el texto anterior a la tabla si hay "Clasificación"
        prev_text = table.find_previous(['h2', 'h3', 'h4'])
        if prev_text and 'Clasificación' in prev_text.get_text():
            clasificacion_table = table
            break
    
    if not clasificacion_table:
        # Si no se encuentra por el método anterior, buscar la primera tabla grande
        clasificacion_table = tables[0] if tables else None
    
    if not clasificacion_table:
        print("No se encontró la tabla de clasificación")
        return None
    
    # Extraer los datos
    rows = clasificacion_table.find_all('tr')
    
    data = []
    headers = []
    
    # Extraer encabezados
    header_row = rows[0]
    for th in header_row.find_all(['th', 'td']):
        headers.append(th.get_text().strip())
    
    # Extraer datos de cada equipo
    for row in rows[1:]:
        cols = row.find_all(['td', 'th'])
        if len(cols) > 1:  # Asegurarse de que sea una fila de datos
            row_data = []
            for col in cols:
                # Limpiar el texto
                text = col.get_text().strip()
                # Eliminar referencias [nota X]
                text = text.split('[')[0].strip()
                row_data.append(text)
            data.append(row_data)
    
    # Crear DataFrame
    df = pd.DataFrame(data, columns=headers[:len(data[0])])
    
    return df


def scrape_multiple_seasons(start_year, end_year):
    """
    Extrae datos de múltiples temporadas de Premier League
    
    Args:
        start_year: Año de inicio (ej: 1992)
        end_year: Año de fin (ej: 2023)
    """
    all_seasons = {}
    
    for year in range(start_year, end_year):
        next_year = year + 1
        season = f"{year}-{str(next_year)[-2:]}"
        
        # Construir URL (ajustar formato según Wikipedia en español)
        url = f"https://es.wikipedia.org/wiki/Premier_League_{season}"
        
        print(f"Extrayendo temporada {season}...")
        
        try:
            df = scrape_premier_league_season(url)
            if df is not None:
                all_seasons[season] = df
                print(f"✓ Temporada {season} extraída correctamente")
            else:
                print(f"✗ No se pudo extraer la temporada {season}")
        except Exception as e:
            print(f"✗ Error en temporada {season}: {str(e)}")
    
    return all_seasons


# Ejemplo de uso: Extraer una temporada específica
if __name__ == "__main__":
    # Ejemplo 1: Extraer temporada 1992-93
    print("=== Extrayendo temporada 1992-93 ===")
    url_1992 = "https://es.wikipedia.org/wiki/Premier_League_1992-93"
    df_1992 = scrape_premier_league_season(url_1992)
    
    if df_1992 is not None:
        print("\nPrimeras filas:")
        print(df_1992.head())
        
        # Guardar a CSV
        df_1992.to_csv('premier_league_1992-93.csv', index=False, encoding='utf-8-sig')
        print("\n✓ Datos guardados en 'premier_league_1992-93.csv'")
    
    print("\n" + "="*50)
    
    # Ejemplo 2: Extraer múltiples temporadas
    print("\n=== Extrayendo múltiples temporadas ===")
    seasons_data = scrape_multiple_seasons(1992, 1995)  # Ejemplo: 1992-93, 1993-94, 1994-95
    
    # Guardar cada temporada en un archivo separado
    for season, df in seasons_data.items():
        filename = f'premier_league_{season}.csv'
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"✓ Guardado: {filename}")
    
    # Opcional: Combinar todas las temporadas en un solo archivo
    if seasons_data:
        combined_df = pd.concat(
            [df.assign(Temporada=season) for season, df in seasons_data.items()],
            ignore_index=True
        )
        combined_df.to_csv('premier_league_todas_temporadas.csv', index=False, encoding='utf-8-sig')
        print(f"\n✓ Todas las temporadas combinadas guardadas en 'premier_league_todas_temporadas.csv'")
